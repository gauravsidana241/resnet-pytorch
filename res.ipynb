{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e4788c8",
   "metadata": {},
   "source": [
    "## About this notebook\n",
    "I have used this notebook to develop deeper understanding of *convolutions* and *convolutional neural network*. This notebook studies **ResNet** and how it solved the network degradation problem with increasing network depth (channels). Resnet does this with shortcut connection or skip connections. There are some notes that explain this a bit, but i believe its best if one learns this themselves. The model uses 2 different blocks - *Basic* and *Bottlneck* depending upon the depth of the resnet, for resnet deeper than 50 layers it is necessary to save computational cost and hence the bottleneck trick - this is also explained a bit in the notebook. I have not trained any models for this one because the goal of this study is essential to understand cnns and it was made simpler with torch summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de4201f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef92273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels=64,out_channels=64, stride=[1,1], down_sample=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride[0], padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride[1], padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.down_sample = down_sample\n",
    "        if down_sample:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=2, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x.clone()\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.down_sample:\n",
    "            input = self.downsample(input)\n",
    "\n",
    "        x += input\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f50507a",
   "metadata": {},
   "source": [
    "# ResNet & Convolutional Neural Networks: Comprehensive Technical Summary\n",
    "\n",
    "## 1. Architecture & Residual Learning\n",
    "\n",
    "**Q: What is the \"Degradation Problem\" and how does ResNet solve it?**\n",
    "* **The Problem**: In deep \"plain\" networks, adding more layers leads to higher training error, which is an optimization issue where deeper systems are harder to train.\n",
    "* **The Solution**: ResNet introduces **Shortcut Connections** that allow the network to learn **Residual Mappings** ($F(x) = H(x) - x$).\n",
    "* **Identity Mapping**: It is mathematically easier for an optimizer to push weights toward zero to achieve an identity mapping than to force a stack of non-linear layers to mimic the input $x$ perfectly.\n",
    "* **Gradient Flow**: The addition operation acts as a \"gradient highway,\" ensuring that early layers receive a strong signal during backpropagation.\n",
    "\n",
    "\n",
    "\n",
    "**Q: Why use a \"Projection\" (1x1 Conv) for downsampling instead of just passing the input?**\n",
    "* **Dimensionality Mismatch**: When the main path ($F(x)$) reduces spatial resolution (via stride) and increases channel depth, the raw input $x$ no longer matches for addition.\n",
    "* **Re-formatting**: The $1 \\times 1$ convolution acts as a \"bridge,\" using a stride of 2 to match the spatial size and a specific number of filters to match the new channel depth.\n",
    "* **Learned Identity**: While it adds a few parameters, the network trains these weights to be the most effective linear transformation of the input for that specific transition.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 2. 3D Convolution & \"The Weight Matrix\"\n",
    "\n",
    "**Q: If a kernel size is 3x3, why does a single filter have more than 9 weights?**\n",
    "* **The 3D Cube**: A kernel must match the depth of the input. If the input has 64 channels, a $3 \\times 3$ kernel is a cube of $3 \\times 3 \\times 64 = 576$ weights.\n",
    "* **The Summation**: During the convolution, the filter performs an element-wise multiplication across all 576 values and sums them into a **single scalar** for that pixel.\n",
    "* **1x1 Projection Weights**: In a $1 \\times 1$ convolution, one filter is a cube of $1 \\times 1 \\times 64 = 64$ weights. This is why it’s called a \"pointwise\" projection; it mixes channels at a single point.\n",
    "\n",
    "\n",
    "\n",
    "**Q: How do we get exactly 64 or 128 output channels?**\n",
    "* **Filter Count**: The number of output channels is determined strictly by how many **unique 3D filters** you choose to slide across the image.\n",
    "* **Stacking**: Filter #1 produces the first 2D output sheet, Filter #2 produces the second, and so on. Stacking these 64 unique sheets creates the 64-channel output.\n",
    "* **Weight Tensor Shape**: Weights are stored as $(C_{out}, C_{in}, K_h, K_w)$.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Execution & Implementation\n",
    "\n",
    "**Q: What happens when I call `model(input)` instead of `model.forward(input)`?**\n",
    "* **The `__call__` Wrapper**: Calling the object directly triggers the `nn.Module.__call__` method, which manages internal state and \"hooks\" before executing your `forward` logic.\n",
    "* **The Stack**: Execution is a \"Russian Doll\" stack: the model's `__call__` runs, then the block's `__call__` runs, and finally each layer's `__call__` runs down to the C++/CUDA math kernels.\n",
    "\n",
    "**Q: Why can I reuse ReLU but not BatchNorm?**\n",
    "* **Stateless vs. Stateful**: ReLU is a \"stateless\" mathematical function—it has no memory or weights. BatchNorm is \"stateful\" because it has learnable parameters ($\\gamma, \\beta$) and tracks running means/variances unique to its position in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12d48120",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, in_channels=64,out_channels=64, kerenel=[1,3,1], stride=[1,2,1], down_sample=False, down_sample_strid=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=kerenel[0], stride=stride[0], bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=kerenel[1], stride=stride[1], padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*4, kernel_size=kerenel[2], stride=stride[2], bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels*4)\n",
    "        self.relu = nn.ReLU(inplace=True) # does it matter where this relu is defined in the order like this\n",
    "\n",
    "        self.down_sample = down_sample\n",
    "        if down_sample:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*4, kernel_size=1, stride=down_sample_strid, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*4)\n",
    "\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        input = x.clone()\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        if self.down_sample:\n",
    "            input = self.downsample(input)\n",
    "\n",
    "        x += input\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f472e382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels=3,num_residual_block=[3,4,6,3],num_class=1000,block_type='normal'):\n",
    "        super(ResNet,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,64,7,2,3,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(True)\n",
    "        self.maxpool = nn.MaxPool2d(3,2,1)\n",
    "\n",
    "        if block_type.lower() == 'bottleneck':    \n",
    "            self.resnet,outchannels = self.__bottlenecks(num_residual_block)\n",
    "        else:\n",
    "            self.resnet,outchannels = self.__layers(num_residual_block)\n",
    "    \n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(in_features=outchannels,out_features=num_class,bias=True)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.resnet(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def __layers(self,num_residual_block):\n",
    "        layer=[]\n",
    "        # layer += [BasicBlock()]*num_residual_block[0]\n",
    "        layer += [BasicBlock() for _ in range(num_residual_block[0])]\n",
    "        inchannels=64\n",
    "        for numOFlayers in num_residual_block[1:]:\n",
    "            stride = [2,1] #updating the stride, the first layer of residual block\n",
    "            # will have a stride of two and the 2nd layer of the residual block have \n",
    "            # a stride of 1\n",
    "            downsample=True\n",
    "            outchannels = inchannels*2\n",
    "            for _ in range(numOFlayers):\n",
    "                layer.append(BasicBlock(inchannels,outchannels,stride,down_sample=downsample))\n",
    "                inchannels = outchannels\n",
    "                downsample = False \n",
    "                stride=[1,1]\n",
    "            \n",
    "        return nn.Sequential(*layer),outchannels\n",
    "\n",
    "    \n",
    "    def __bottlenecks(self,numres):\n",
    "        \n",
    "        layer=[]\n",
    "        \n",
    "        stride = [1,1,1]\n",
    "        dnStride=1\n",
    "        inchan = 64\n",
    "        for i,numOFlayers in enumerate(numres):\n",
    "            dn_sample = True\n",
    "            outchan = 64*(2**i)\n",
    "\n",
    "            for _ in range(numOFlayers):\n",
    "                layer+=[ \n",
    "                    Bottleneck(inchan,outchan,stride=stride,\n",
    "                    down_sample=dn_sample,down_sample_strid=dnStride)\n",
    "                ]\n",
    "                inchan = outchan*4\n",
    "                dn_sample = False\n",
    "                stride = [1,1,1]   \n",
    "            dn_sample=True \n",
    "            stride = [1,2,1]\n",
    "            dnStride=2\n",
    "            \n",
    "\n",
    "        return nn.Sequential(*layer),inchan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe95b40",
   "metadata": {},
   "source": [
    "# ResNet Implementation & Architectural Summary\n",
    "\n",
    "### 1. The \"Stem\" (Initial Preparation)\n",
    "* **Purpose**: Aggressively reduces high-resolution input (e.g., 224x224) and expands channels to 64 before entering expensive residual stages.\n",
    "* **Output Shape Math**: The initial 7x7 conv (stride 2, padding 3) results in **112x112** because $O = \\lfloor \\frac{224 - 7 + (2 \\times 3)}{2} \\rfloor + 1 = 112$.\n",
    "* **Parameter Count**: For `conv1` (7x7, 3 in, 64 out, bias=False), the math is $7 \\times 7 \\times 3 \\times 64 = \\mathbf{9,408}$.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. The Residual Concept: Accumulation over Transformation\n",
    "* **Identity vs. Change**: ResNet layers learn the **change** (residual $F(x)$) needed for the current state rather than a completely new representation.\n",
    "* **No \"Resetting\"**: Because of the addition $x + F(x)$, information persists throughout the network; if a block learns nothing, the shortcut simply passes the existing data forward.\n",
    "* **Feature Persistence**: The final signal is the original image plus hundreds of incremental refinements stacked on top of it.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 3. BasicBlock vs. Bottleneck\n",
    "* **BasicBlock**: Used in ResNet-18/34. Consists of two 3x3 convolutions.\n",
    "* **Bottleneck**: Used in ResNet-50+. Uses a **1x1 (Squeeze) -> 3x3 (Process) -> 1x1 (Expand)** strategy to save computation by reducing channel depth before spatial work.\n",
    "* **The \"Balloon\" Effect**: In Stage 1, the first block expands 64 to 256. Every subsequent block in that stage is a true bottleneck ($256 \\rightarrow 64 \\rightarrow 256$).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Dimensionality & Downsampling\n",
    "* **Strict Addition**: For $x + F(x)$, the Batch, Channel, Height, and Width must match **exactly**.\n",
    "* **Projection Shortcut**: Used only in the **first block of a stage** to fix mismatches when spatial size halves (Stride 2) and depth doubles.\n",
    "* **Downsample Logic**: Subsequent blocks in a stage use **Identity Mapping** because shapes already match, saving millions of multiplications and preserving gradient flow.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Model Scaling & Naming\n",
    "* **ResNet-18 Math**: Only weighted layers in the main path are counted. $1 (\\text{stem}) + (2 \\text{ layers/block} \\times [2+2+2+2]) + 1 (\\text{fc}) = 18$.\n",
    "* **Channel Doubling**: We double channels as we halve resolution to maintain constant computational complexity and compensate for lost spatial detail.\n",
    "* **Global Average Pooling**: Collapses the final 7x7 spatial grid into a single feature vector, removing spatial location but keeping the \"rich\" accumulated signal for the final classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fa4c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  resnet18(**kwargs):\n",
    "    return ResNet(num_residual_block=[2,2,2,2],**kwargs)\n",
    "\n",
    "def resnet34(**kwargs):\n",
    "    return ResNet(num_residual_block=[3,4,6,3],**kwargs)\n",
    "\n",
    "def resnet50(**kwargs):\n",
    "    return ResNet(num_residual_block=[3,4,6,3],block_type='bottleneck',**kwargs)\n",
    "\n",
    "def resnet101(**kwargs):\n",
    "    return ResNet(num_residual_block=[3,4,23,3],block_type='bottleneck',**kwargs)\n",
    "\n",
    "def resnet152(**kwargs):\n",
    "    return ResNet(num_residual_block=[3,8,36,3],block_type='bottleneck',**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5261ee6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 28, 28]             256\n",
      "             ReLU-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 28, 28]             256\n",
      "           Conv2d-24          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 28, 28]             256\n",
      "             ReLU-26          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-27          [-1, 128, 28, 28]               0\n",
      "           Conv2d-28          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 28, 28]             256\n",
      "             ReLU-30          [-1, 128, 28, 28]               0\n",
      "           Conv2d-31          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 14, 14]             512\n",
      "             ReLU-37          [-1, 256, 14, 14]               0\n",
      "           Conv2d-38          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 14, 14]             512\n",
      "           Conv2d-40          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 14, 14]             512\n",
      "             ReLU-42          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-43          [-1, 256, 14, 14]               0\n",
      "           Conv2d-44          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 14, 14]             512\n",
      "             ReLU-46          [-1, 256, 14, 14]               0\n",
      "           Conv2d-47          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 14, 14]             512\n",
      "             ReLU-49          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-50          [-1, 256, 14, 14]               0\n",
      "           Conv2d-51            [-1, 512, 7, 7]       1,179,648\n",
      "      BatchNorm2d-52            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-53            [-1, 512, 7, 7]               0\n",
      "           Conv2d-54            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-55            [-1, 512, 7, 7]           1,024\n",
      "           Conv2d-56            [-1, 512, 7, 7]         131,072\n",
      "      BatchNorm2d-57            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-58            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-59            [-1, 512, 7, 7]               0\n",
      "           Conv2d-60            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-61            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-62            [-1, 512, 7, 7]               0\n",
      "           Conv2d-63            [-1, 512, 7, 7]       2,359,296\n",
      "      BatchNorm2d-64            [-1, 512, 7, 7]           1,024\n",
      "             ReLU-65            [-1, 512, 7, 7]               0\n",
      "       BasicBlock-66            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "           Linear-68                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 11,689,512\n",
      "Trainable params: 11,689,512\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 62.79\n",
      "Params size (MB): 44.59\n",
      "Estimated Total Size (MB): 107.96\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model118 = resnet18().to(device=device)\n",
    "summary(model118, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42756daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-11           [-1, 64, 56, 56]               0\n",
      "           Conv2d-12           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-13           [-1, 64, 56, 56]             128\n",
      "             ReLU-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-16           [-1, 64, 56, 56]             128\n",
      "             ReLU-17           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-18           [-1, 64, 56, 56]               0\n",
      "           Conv2d-19           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-20           [-1, 64, 56, 56]             128\n",
      "             ReLU-21           [-1, 64, 56, 56]               0\n",
      "           Conv2d-22           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-23           [-1, 64, 56, 56]             128\n",
      "             ReLU-24           [-1, 64, 56, 56]               0\n",
      "       BasicBlock-25           [-1, 64, 56, 56]               0\n",
      "           Conv2d-26          [-1, 128, 28, 28]          73,728\n",
      "      BatchNorm2d-27          [-1, 128, 28, 28]             256\n",
      "             ReLU-28          [-1, 128, 28, 28]               0\n",
      "           Conv2d-29          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-30          [-1, 128, 28, 28]             256\n",
      "           Conv2d-31          [-1, 128, 28, 28]           8,192\n",
      "      BatchNorm2d-32          [-1, 128, 28, 28]             256\n",
      "             ReLU-33          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "             ReLU-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-39          [-1, 128, 28, 28]             256\n",
      "             ReLU-40          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-41          [-1, 128, 28, 28]               0\n",
      "           Conv2d-42          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-43          [-1, 128, 28, 28]             256\n",
      "             ReLU-44          [-1, 128, 28, 28]               0\n",
      "           Conv2d-45          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-46          [-1, 128, 28, 28]             256\n",
      "             ReLU-47          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-48          [-1, 128, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "       BasicBlock-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 256, 14, 14]         294,912\n",
      "      BatchNorm2d-57          [-1, 256, 14, 14]             512\n",
      "             ReLU-58          [-1, 256, 14, 14]               0\n",
      "           Conv2d-59          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-60          [-1, 256, 14, 14]             512\n",
      "           Conv2d-61          [-1, 256, 14, 14]          32,768\n",
      "      BatchNorm2d-62          [-1, 256, 14, 14]             512\n",
      "             ReLU-63          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-64          [-1, 256, 14, 14]               0\n",
      "           Conv2d-65          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-66          [-1, 256, 14, 14]             512\n",
      "             ReLU-67          [-1, 256, 14, 14]               0\n",
      "           Conv2d-68          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-69          [-1, 256, 14, 14]             512\n",
      "             ReLU-70          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-71          [-1, 256, 14, 14]               0\n",
      "           Conv2d-72          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-73          [-1, 256, 14, 14]             512\n",
      "             ReLU-74          [-1, 256, 14, 14]               0\n",
      "           Conv2d-75          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-76          [-1, 256, 14, 14]             512\n",
      "             ReLU-77          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-78          [-1, 256, 14, 14]               0\n",
      "           Conv2d-79          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-80          [-1, 256, 14, 14]             512\n",
      "             ReLU-81          [-1, 256, 14, 14]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-85          [-1, 256, 14, 14]               0\n",
      "           Conv2d-86          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-87          [-1, 256, 14, 14]             512\n",
      "             ReLU-88          [-1, 256, 14, 14]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-92          [-1, 256, 14, 14]               0\n",
      "           Conv2d-93          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-94          [-1, 256, 14, 14]             512\n",
      "             ReLU-95          [-1, 256, 14, 14]               0\n",
      "           Conv2d-96          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-97          [-1, 256, 14, 14]             512\n",
      "             ReLU-98          [-1, 256, 14, 14]               0\n",
      "       BasicBlock-99          [-1, 256, 14, 14]               0\n",
      "          Conv2d-100            [-1, 512, 7, 7]       1,179,648\n",
      "     BatchNorm2d-101            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-102            [-1, 512, 7, 7]               0\n",
      "          Conv2d-103            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-104            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-105            [-1, 512, 7, 7]         131,072\n",
      "     BatchNorm2d-106            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-107            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-108            [-1, 512, 7, 7]               0\n",
      "          Conv2d-109            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-110            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-111            [-1, 512, 7, 7]               0\n",
      "          Conv2d-112            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-113            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-114            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-115            [-1, 512, 7, 7]               0\n",
      "          Conv2d-116            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-117            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-118            [-1, 512, 7, 7]               0\n",
      "          Conv2d-119            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-120            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-121            [-1, 512, 7, 7]               0\n",
      "      BasicBlock-122            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0\n",
      "          Linear-124                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 21,797,672\n",
      "Trainable params: 21,797,672\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 96.29\n",
      "Params size (MB): 83.15\n",
      "Estimated Total Size (MB): 180.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model34 = resnet34().to(device=device)\n",
    "summary(model34,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80885c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "             ReLU-13          [-1, 256, 56, 56]               0\n",
      "           Conv2d-14          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-15          [-1, 256, 56, 56]             512\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-17          [-1, 256, 56, 56]               0\n",
      "           Conv2d-18           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-19           [-1, 64, 56, 56]             128\n",
      "             ReLU-20           [-1, 64, 56, 56]               0\n",
      "           Conv2d-21           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "           Conv2d-24          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-25          [-1, 256, 56, 56]             512\n",
      "             ReLU-26          [-1, 256, 56, 56]               0\n",
      "             ReLU-27          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-28          [-1, 256, 56, 56]               0\n",
      "           Conv2d-29           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
      "             ReLU-31           [-1, 64, 56, 56]               0\n",
      "           Conv2d-32           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-33           [-1, 64, 56, 56]             128\n",
      "             ReLU-34           [-1, 64, 56, 56]               0\n",
      "           Conv2d-35          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-36          [-1, 256, 56, 56]             512\n",
      "             ReLU-37          [-1, 256, 56, 56]               0\n",
      "             ReLU-38          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-39          [-1, 256, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-41          [-1, 128, 56, 56]             256\n",
      "             ReLU-42          [-1, 128, 56, 56]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-51          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-52          [-1, 512, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "             ReLU-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "             ReLU-62          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-63          [-1, 512, 28, 28]               0\n",
      "           Conv2d-64          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 28, 28]             256\n",
      "             ReLU-66          [-1, 128, 28, 28]               0\n",
      "           Conv2d-67          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "           Conv2d-70          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-72          [-1, 512, 28, 28]               0\n",
      "             ReLU-73          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-74          [-1, 512, 28, 28]               0\n",
      "           Conv2d-75          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 128, 28, 28]             256\n",
      "             ReLU-77          [-1, 128, 28, 28]               0\n",
      "           Conv2d-78          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-79          [-1, 128, 28, 28]             256\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-82          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-83          [-1, 512, 28, 28]               0\n",
      "             ReLU-84          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-85          [-1, 512, 28, 28]               0\n",
      "           Conv2d-86          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-87          [-1, 256, 28, 28]             512\n",
      "             ReLU-88          [-1, 256, 28, 28]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "           Conv2d-92         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-93         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-94         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-95         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-96         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-97         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-98         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-99          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "            ReLU-101          [-1, 256, 14, 14]               0\n",
      "          Conv2d-102          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-103          [-1, 256, 14, 14]             512\n",
      "            ReLU-104          [-1, 256, 14, 14]               0\n",
      "          Conv2d-105         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-106         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-107         [-1, 1024, 14, 14]               0\n",
      "            ReLU-108         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-109         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-110          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-111          [-1, 256, 14, 14]             512\n",
      "            ReLU-112          [-1, 256, 14, 14]               0\n",
      "          Conv2d-113          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-114          [-1, 256, 14, 14]             512\n",
      "            ReLU-115          [-1, 256, 14, 14]               0\n",
      "          Conv2d-116         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-117         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-118         [-1, 1024, 14, 14]               0\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "            ReLU-130         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-131         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-132          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-133          [-1, 256, 14, 14]             512\n",
      "            ReLU-134          [-1, 256, 14, 14]               0\n",
      "          Conv2d-135          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-136          [-1, 256, 14, 14]             512\n",
      "            ReLU-137          [-1, 256, 14, 14]               0\n",
      "          Conv2d-138         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-139         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-140         [-1, 1024, 14, 14]               0\n",
      "            ReLU-141         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-142         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-143          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-144          [-1, 256, 14, 14]             512\n",
      "            ReLU-145          [-1, 256, 14, 14]               0\n",
      "          Conv2d-146          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-147          [-1, 256, 14, 14]             512\n",
      "            ReLU-148          [-1, 256, 14, 14]               0\n",
      "          Conv2d-149         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-150         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-151         [-1, 1024, 14, 14]               0\n",
      "            ReLU-152         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-153         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-154          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-155          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-156          [-1, 512, 14, 14]               0\n",
      "          Conv2d-157            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-158            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-159            [-1, 512, 7, 7]               0\n",
      "          Conv2d-160           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-161           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-164           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-165           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-166           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-167            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-168            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-169            [-1, 512, 7, 7]               0\n",
      "          Conv2d-170            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-171            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-172            [-1, 512, 7, 7]               0\n",
      "          Conv2d-173           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-174           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-175           [-1, 2048, 7, 7]               0\n",
      "            ReLU-176           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-177           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-178            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-179            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-180            [-1, 512, 7, 7]               0\n",
      "          Conv2d-181            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-182            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-183            [-1, 512, 7, 7]               0\n",
      "          Conv2d-184           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-185           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-186           [-1, 2048, 7, 7]               0\n",
      "            ReLU-187           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-188           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-189           [-1, 2048, 1, 1]               0\n",
      "          Linear-190                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 328.67\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 426.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model50 = resnet50().to(device=device)\n",
    "summary(model50,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4436ee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "             ReLU-13          [-1, 256, 56, 56]               0\n",
      "           Conv2d-14          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-15          [-1, 256, 56, 56]             512\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-17          [-1, 256, 56, 56]               0\n",
      "           Conv2d-18           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-19           [-1, 64, 56, 56]             128\n",
      "             ReLU-20           [-1, 64, 56, 56]               0\n",
      "           Conv2d-21           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "           Conv2d-24          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-25          [-1, 256, 56, 56]             512\n",
      "             ReLU-26          [-1, 256, 56, 56]               0\n",
      "             ReLU-27          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-28          [-1, 256, 56, 56]               0\n",
      "           Conv2d-29           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
      "             ReLU-31           [-1, 64, 56, 56]               0\n",
      "           Conv2d-32           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-33           [-1, 64, 56, 56]             128\n",
      "             ReLU-34           [-1, 64, 56, 56]               0\n",
      "           Conv2d-35          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-36          [-1, 256, 56, 56]             512\n",
      "             ReLU-37          [-1, 256, 56, 56]               0\n",
      "             ReLU-38          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-39          [-1, 256, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-41          [-1, 128, 56, 56]             256\n",
      "             ReLU-42          [-1, 128, 56, 56]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-51          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-52          [-1, 512, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "             ReLU-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "             ReLU-62          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-63          [-1, 512, 28, 28]               0\n",
      "           Conv2d-64          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 28, 28]             256\n",
      "             ReLU-66          [-1, 128, 28, 28]               0\n",
      "           Conv2d-67          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "           Conv2d-70          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-72          [-1, 512, 28, 28]               0\n",
      "             ReLU-73          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-74          [-1, 512, 28, 28]               0\n",
      "           Conv2d-75          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 128, 28, 28]             256\n",
      "             ReLU-77          [-1, 128, 28, 28]               0\n",
      "           Conv2d-78          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-79          [-1, 128, 28, 28]             256\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-82          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-83          [-1, 512, 28, 28]               0\n",
      "             ReLU-84          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-85          [-1, 512, 28, 28]               0\n",
      "           Conv2d-86          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-87          [-1, 256, 28, 28]             512\n",
      "             ReLU-88          [-1, 256, 28, 28]               0\n",
      "           Conv2d-89          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 14, 14]             512\n",
      "             ReLU-91          [-1, 256, 14, 14]               0\n",
      "           Conv2d-92         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-93         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-94         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-95         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-96         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-97         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-98         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-99          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "            ReLU-101          [-1, 256, 14, 14]               0\n",
      "          Conv2d-102          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-103          [-1, 256, 14, 14]             512\n",
      "            ReLU-104          [-1, 256, 14, 14]               0\n",
      "          Conv2d-105         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-106         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-107         [-1, 1024, 14, 14]               0\n",
      "            ReLU-108         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-109         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-110          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-111          [-1, 256, 14, 14]             512\n",
      "            ReLU-112          [-1, 256, 14, 14]               0\n",
      "          Conv2d-113          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-114          [-1, 256, 14, 14]             512\n",
      "            ReLU-115          [-1, 256, 14, 14]               0\n",
      "          Conv2d-116         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-117         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-118         [-1, 1024, 14, 14]               0\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "            ReLU-130         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-131         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-132          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-133          [-1, 256, 14, 14]             512\n",
      "            ReLU-134          [-1, 256, 14, 14]               0\n",
      "          Conv2d-135          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-136          [-1, 256, 14, 14]             512\n",
      "            ReLU-137          [-1, 256, 14, 14]               0\n",
      "          Conv2d-138         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-139         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-140         [-1, 1024, 14, 14]               0\n",
      "            ReLU-141         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-142         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-143          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-144          [-1, 256, 14, 14]             512\n",
      "            ReLU-145          [-1, 256, 14, 14]               0\n",
      "          Conv2d-146          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-147          [-1, 256, 14, 14]             512\n",
      "            ReLU-148          [-1, 256, 14, 14]               0\n",
      "          Conv2d-149         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-150         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-151         [-1, 1024, 14, 14]               0\n",
      "            ReLU-152         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-153         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-158          [-1, 256, 14, 14]             512\n",
      "            ReLU-159          [-1, 256, 14, 14]               0\n",
      "          Conv2d-160         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-161         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-162         [-1, 1024, 14, 14]               0\n",
      "            ReLU-163         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-164         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-165          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-166          [-1, 256, 14, 14]             512\n",
      "            ReLU-167          [-1, 256, 14, 14]               0\n",
      "          Conv2d-168          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-169          [-1, 256, 14, 14]             512\n",
      "            ReLU-170          [-1, 256, 14, 14]               0\n",
      "          Conv2d-171         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-172         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-173         [-1, 1024, 14, 14]               0\n",
      "            ReLU-174         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-175         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-176          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-177          [-1, 256, 14, 14]             512\n",
      "            ReLU-178          [-1, 256, 14, 14]               0\n",
      "          Conv2d-179          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-180          [-1, 256, 14, 14]             512\n",
      "            ReLU-181          [-1, 256, 14, 14]               0\n",
      "          Conv2d-182         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-183         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-184         [-1, 1024, 14, 14]               0\n",
      "            ReLU-185         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-186         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-187          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-188          [-1, 256, 14, 14]             512\n",
      "            ReLU-189          [-1, 256, 14, 14]               0\n",
      "          Conv2d-190          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-191          [-1, 256, 14, 14]             512\n",
      "            ReLU-192          [-1, 256, 14, 14]               0\n",
      "          Conv2d-193         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-194         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-195         [-1, 1024, 14, 14]               0\n",
      "            ReLU-196         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-197         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-198          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-199          [-1, 256, 14, 14]             512\n",
      "            ReLU-200          [-1, 256, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-205         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-206         [-1, 1024, 14, 14]               0\n",
      "            ReLU-207         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-208         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-209          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-210          [-1, 256, 14, 14]             512\n",
      "            ReLU-211          [-1, 256, 14, 14]               0\n",
      "          Conv2d-212          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-213          [-1, 256, 14, 14]             512\n",
      "            ReLU-214          [-1, 256, 14, 14]               0\n",
      "          Conv2d-215         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-216         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-217         [-1, 1024, 14, 14]               0\n",
      "            ReLU-218         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-219         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-220          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-221          [-1, 256, 14, 14]             512\n",
      "            ReLU-222          [-1, 256, 14, 14]               0\n",
      "          Conv2d-223          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-224          [-1, 256, 14, 14]             512\n",
      "            ReLU-225          [-1, 256, 14, 14]               0\n",
      "          Conv2d-226         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-227         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-228         [-1, 1024, 14, 14]               0\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "            ReLU-240         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-241         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-242          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-243          [-1, 256, 14, 14]             512\n",
      "            ReLU-244          [-1, 256, 14, 14]               0\n",
      "          Conv2d-245          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-246          [-1, 256, 14, 14]             512\n",
      "            ReLU-247          [-1, 256, 14, 14]               0\n",
      "          Conv2d-248         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-249         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-250         [-1, 1024, 14, 14]               0\n",
      "            ReLU-251         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-252         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-253          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-254          [-1, 256, 14, 14]             512\n",
      "            ReLU-255          [-1, 256, 14, 14]               0\n",
      "          Conv2d-256          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-257          [-1, 256, 14, 14]             512\n",
      "            ReLU-258          [-1, 256, 14, 14]               0\n",
      "          Conv2d-259         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-260         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-261         [-1, 1024, 14, 14]               0\n",
      "            ReLU-262         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-263         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-268          [-1, 256, 14, 14]             512\n",
      "            ReLU-269          [-1, 256, 14, 14]               0\n",
      "          Conv2d-270         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-271         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-272         [-1, 1024, 14, 14]               0\n",
      "            ReLU-273         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-274         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-275          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-276          [-1, 256, 14, 14]             512\n",
      "            ReLU-277          [-1, 256, 14, 14]               0\n",
      "          Conv2d-278          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-279          [-1, 256, 14, 14]             512\n",
      "            ReLU-280          [-1, 256, 14, 14]               0\n",
      "          Conv2d-281         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-282         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-283         [-1, 1024, 14, 14]               0\n",
      "            ReLU-284         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-285         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-286          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-287          [-1, 256, 14, 14]             512\n",
      "            ReLU-288          [-1, 256, 14, 14]               0\n",
      "          Conv2d-289          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-290          [-1, 256, 14, 14]             512\n",
      "            ReLU-291          [-1, 256, 14, 14]               0\n",
      "          Conv2d-292         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-293         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-294         [-1, 1024, 14, 14]               0\n",
      "            ReLU-295         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-296         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-297          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-298          [-1, 256, 14, 14]             512\n",
      "            ReLU-299          [-1, 256, 14, 14]               0\n",
      "          Conv2d-300          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-301          [-1, 256, 14, 14]             512\n",
      "            ReLU-302          [-1, 256, 14, 14]               0\n",
      "          Conv2d-303         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-304         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-305         [-1, 1024, 14, 14]               0\n",
      "            ReLU-306         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-307         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-308          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-309          [-1, 256, 14, 14]             512\n",
      "            ReLU-310          [-1, 256, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-315         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-316         [-1, 1024, 14, 14]               0\n",
      "            ReLU-317         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-318         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-319          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-320          [-1, 256, 14, 14]             512\n",
      "            ReLU-321          [-1, 256, 14, 14]               0\n",
      "          Conv2d-322          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-323          [-1, 256, 14, 14]             512\n",
      "            ReLU-324          [-1, 256, 14, 14]               0\n",
      "          Conv2d-325         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-326         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-327         [-1, 1024, 14, 14]               0\n",
      "            ReLU-328         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-329         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-330          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-331          [-1, 256, 14, 14]             512\n",
      "            ReLU-332          [-1, 256, 14, 14]               0\n",
      "          Conv2d-333          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-334          [-1, 256, 14, 14]             512\n",
      "            ReLU-335          [-1, 256, 14, 14]               0\n",
      "          Conv2d-336         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-337         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-338         [-1, 1024, 14, 14]               0\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-342          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-343          [-1, 512, 14, 14]               0\n",
      "          Conv2d-344            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-345            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-346            [-1, 512, 7, 7]               0\n",
      "          Conv2d-347           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-348           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-349           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-350           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-351           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-352           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-353           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-354            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-355            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-356            [-1, 512, 7, 7]               0\n",
      "          Conv2d-357            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-358            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-359            [-1, 512, 7, 7]               0\n",
      "          Conv2d-360           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-361           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-362           [-1, 2048, 7, 7]               0\n",
      "            ReLU-363           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-364           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-365            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-366            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-367            [-1, 512, 7, 7]               0\n",
      "          Conv2d-368            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-369            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-370            [-1, 512, 7, 7]               0\n",
      "          Conv2d-371           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-372           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-373           [-1, 2048, 7, 7]               0\n",
      "            ReLU-374           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-375           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-376           [-1, 2048, 1, 1]               0\n",
      "          Linear-377                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 44,549,160\n",
      "Trainable params: 44,549,160\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 497.87\n",
      "Params size (MB): 169.94\n",
      "Estimated Total Size (MB): 668.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model101 = resnet101().to(device=device)\n",
    "summary(model101,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5dbcb67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "             ReLU-13          [-1, 256, 56, 56]               0\n",
      "           Conv2d-14          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-15          [-1, 256, 56, 56]             512\n",
      "             ReLU-16          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-17          [-1, 256, 56, 56]               0\n",
      "           Conv2d-18           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-19           [-1, 64, 56, 56]             128\n",
      "             ReLU-20           [-1, 64, 56, 56]               0\n",
      "           Conv2d-21           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 56, 56]             128\n",
      "             ReLU-23           [-1, 64, 56, 56]               0\n",
      "           Conv2d-24          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-25          [-1, 256, 56, 56]             512\n",
      "             ReLU-26          [-1, 256, 56, 56]               0\n",
      "             ReLU-27          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-28          [-1, 256, 56, 56]               0\n",
      "           Conv2d-29           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-30           [-1, 64, 56, 56]             128\n",
      "             ReLU-31           [-1, 64, 56, 56]               0\n",
      "           Conv2d-32           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-33           [-1, 64, 56, 56]             128\n",
      "             ReLU-34           [-1, 64, 56, 56]               0\n",
      "           Conv2d-35          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-36          [-1, 256, 56, 56]             512\n",
      "             ReLU-37          [-1, 256, 56, 56]               0\n",
      "             ReLU-38          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-39          [-1, 256, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-41          [-1, 128, 56, 56]             256\n",
      "             ReLU-42          [-1, 128, 56, 56]               0\n",
      "           Conv2d-43          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 28, 28]             256\n",
      "             ReLU-45          [-1, 128, 28, 28]               0\n",
      "           Conv2d-46          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-51          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-52          [-1, 512, 28, 28]               0\n",
      "           Conv2d-53          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 28, 28]             256\n",
      "             ReLU-55          [-1, 128, 28, 28]               0\n",
      "           Conv2d-56          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 28, 28]             256\n",
      "             ReLU-58          [-1, 128, 28, 28]               0\n",
      "           Conv2d-59          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-61          [-1, 512, 28, 28]               0\n",
      "             ReLU-62          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-63          [-1, 512, 28, 28]               0\n",
      "           Conv2d-64          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 28, 28]             256\n",
      "             ReLU-66          [-1, 128, 28, 28]               0\n",
      "           Conv2d-67          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 28, 28]             256\n",
      "             ReLU-69          [-1, 128, 28, 28]               0\n",
      "           Conv2d-70          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-72          [-1, 512, 28, 28]               0\n",
      "             ReLU-73          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-74          [-1, 512, 28, 28]               0\n",
      "           Conv2d-75          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 128, 28, 28]             256\n",
      "             ReLU-77          [-1, 128, 28, 28]               0\n",
      "           Conv2d-78          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-79          [-1, 128, 28, 28]             256\n",
      "             ReLU-80          [-1, 128, 28, 28]               0\n",
      "           Conv2d-81          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-82          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-83          [-1, 512, 28, 28]               0\n",
      "             ReLU-84          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-85          [-1, 512, 28, 28]               0\n",
      "           Conv2d-86          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-87          [-1, 128, 28, 28]             256\n",
      "             ReLU-88          [-1, 128, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-93          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-94          [-1, 512, 28, 28]               0\n",
      "             ReLU-95          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-96          [-1, 512, 28, 28]               0\n",
      "           Conv2d-97          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-98          [-1, 128, 28, 28]             256\n",
      "             ReLU-99          [-1, 128, 28, 28]               0\n",
      "          Conv2d-100          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-101          [-1, 128, 28, 28]             256\n",
      "            ReLU-102          [-1, 128, 28, 28]               0\n",
      "          Conv2d-103          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-104          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-105          [-1, 512, 28, 28]               0\n",
      "            ReLU-106          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-107          [-1, 512, 28, 28]               0\n",
      "          Conv2d-108          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-109          [-1, 128, 28, 28]             256\n",
      "            ReLU-110          [-1, 128, 28, 28]               0\n",
      "          Conv2d-111          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-112          [-1, 128, 28, 28]             256\n",
      "            ReLU-113          [-1, 128, 28, 28]               0\n",
      "          Conv2d-114          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-115          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-116          [-1, 512, 28, 28]               0\n",
      "            ReLU-117          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-120          [-1, 128, 28, 28]             256\n",
      "            ReLU-121          [-1, 128, 28, 28]               0\n",
      "          Conv2d-122          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-123          [-1, 128, 28, 28]             256\n",
      "            ReLU-124          [-1, 128, 28, 28]               0\n",
      "          Conv2d-125          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-126          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-127          [-1, 512, 28, 28]               0\n",
      "            ReLU-128          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-129          [-1, 512, 28, 28]               0\n",
      "          Conv2d-130          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-131          [-1, 256, 28, 28]             512\n",
      "            ReLU-132          [-1, 256, 28, 28]               0\n",
      "          Conv2d-133          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-134          [-1, 256, 14, 14]             512\n",
      "            ReLU-135          [-1, 256, 14, 14]               0\n",
      "          Conv2d-136         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-137         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-138         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-139         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-140         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-141         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-142         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-143          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-144          [-1, 256, 14, 14]             512\n",
      "            ReLU-145          [-1, 256, 14, 14]               0\n",
      "          Conv2d-146          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-147          [-1, 256, 14, 14]             512\n",
      "            ReLU-148          [-1, 256, 14, 14]               0\n",
      "          Conv2d-149         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-150         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-151         [-1, 1024, 14, 14]               0\n",
      "            ReLU-152         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-153         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-158          [-1, 256, 14, 14]             512\n",
      "            ReLU-159          [-1, 256, 14, 14]               0\n",
      "          Conv2d-160         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-161         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-162         [-1, 1024, 14, 14]               0\n",
      "            ReLU-163         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-164         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-165          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-166          [-1, 256, 14, 14]             512\n",
      "            ReLU-167          [-1, 256, 14, 14]               0\n",
      "          Conv2d-168          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-169          [-1, 256, 14, 14]             512\n",
      "            ReLU-170          [-1, 256, 14, 14]               0\n",
      "          Conv2d-171         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-172         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-173         [-1, 1024, 14, 14]               0\n",
      "            ReLU-174         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-175         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-176          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-177          [-1, 256, 14, 14]             512\n",
      "            ReLU-178          [-1, 256, 14, 14]               0\n",
      "          Conv2d-179          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-180          [-1, 256, 14, 14]             512\n",
      "            ReLU-181          [-1, 256, 14, 14]               0\n",
      "          Conv2d-182         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-183         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-184         [-1, 1024, 14, 14]               0\n",
      "            ReLU-185         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-186         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-187          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-188          [-1, 256, 14, 14]             512\n",
      "            ReLU-189          [-1, 256, 14, 14]               0\n",
      "          Conv2d-190          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-191          [-1, 256, 14, 14]             512\n",
      "            ReLU-192          [-1, 256, 14, 14]               0\n",
      "          Conv2d-193         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-194         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-195         [-1, 1024, 14, 14]               0\n",
      "            ReLU-196         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-197         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-198          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-199          [-1, 256, 14, 14]             512\n",
      "            ReLU-200          [-1, 256, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-205         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-206         [-1, 1024, 14, 14]               0\n",
      "            ReLU-207         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-208         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-209          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-210          [-1, 256, 14, 14]             512\n",
      "            ReLU-211          [-1, 256, 14, 14]               0\n",
      "          Conv2d-212          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-213          [-1, 256, 14, 14]             512\n",
      "            ReLU-214          [-1, 256, 14, 14]               0\n",
      "          Conv2d-215         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-216         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-217         [-1, 1024, 14, 14]               0\n",
      "            ReLU-218         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-219         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-220          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-221          [-1, 256, 14, 14]             512\n",
      "            ReLU-222          [-1, 256, 14, 14]               0\n",
      "          Conv2d-223          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-224          [-1, 256, 14, 14]             512\n",
      "            ReLU-225          [-1, 256, 14, 14]               0\n",
      "          Conv2d-226         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-227         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-228         [-1, 1024, 14, 14]               0\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "            ReLU-240         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-241         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-242          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-243          [-1, 256, 14, 14]             512\n",
      "            ReLU-244          [-1, 256, 14, 14]               0\n",
      "          Conv2d-245          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-246          [-1, 256, 14, 14]             512\n",
      "            ReLU-247          [-1, 256, 14, 14]               0\n",
      "          Conv2d-248         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-249         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-250         [-1, 1024, 14, 14]               0\n",
      "            ReLU-251         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-252         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-253          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-254          [-1, 256, 14, 14]             512\n",
      "            ReLU-255          [-1, 256, 14, 14]               0\n",
      "          Conv2d-256          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-257          [-1, 256, 14, 14]             512\n",
      "            ReLU-258          [-1, 256, 14, 14]               0\n",
      "          Conv2d-259         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-260         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-261         [-1, 1024, 14, 14]               0\n",
      "            ReLU-262         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-263         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-268          [-1, 256, 14, 14]             512\n",
      "            ReLU-269          [-1, 256, 14, 14]               0\n",
      "          Conv2d-270         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-271         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-272         [-1, 1024, 14, 14]               0\n",
      "            ReLU-273         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-274         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-275          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-276          [-1, 256, 14, 14]             512\n",
      "            ReLU-277          [-1, 256, 14, 14]               0\n",
      "          Conv2d-278          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-279          [-1, 256, 14, 14]             512\n",
      "            ReLU-280          [-1, 256, 14, 14]               0\n",
      "          Conv2d-281         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-282         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-283         [-1, 1024, 14, 14]               0\n",
      "            ReLU-284         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-285         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-286          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-287          [-1, 256, 14, 14]             512\n",
      "            ReLU-288          [-1, 256, 14, 14]               0\n",
      "          Conv2d-289          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-290          [-1, 256, 14, 14]             512\n",
      "            ReLU-291          [-1, 256, 14, 14]               0\n",
      "          Conv2d-292         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-293         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-294         [-1, 1024, 14, 14]               0\n",
      "            ReLU-295         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-296         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-297          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-298          [-1, 256, 14, 14]             512\n",
      "            ReLU-299          [-1, 256, 14, 14]               0\n",
      "          Conv2d-300          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-301          [-1, 256, 14, 14]             512\n",
      "            ReLU-302          [-1, 256, 14, 14]               0\n",
      "          Conv2d-303         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-304         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-305         [-1, 1024, 14, 14]               0\n",
      "            ReLU-306         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-307         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-308          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-309          [-1, 256, 14, 14]             512\n",
      "            ReLU-310          [-1, 256, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-315         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-316         [-1, 1024, 14, 14]               0\n",
      "            ReLU-317         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-318         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-319          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-320          [-1, 256, 14, 14]             512\n",
      "            ReLU-321          [-1, 256, 14, 14]               0\n",
      "          Conv2d-322          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-323          [-1, 256, 14, 14]             512\n",
      "            ReLU-324          [-1, 256, 14, 14]               0\n",
      "          Conv2d-325         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-326         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-327         [-1, 1024, 14, 14]               0\n",
      "            ReLU-328         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-329         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-330          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-331          [-1, 256, 14, 14]             512\n",
      "            ReLU-332          [-1, 256, 14, 14]               0\n",
      "          Conv2d-333          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-334          [-1, 256, 14, 14]             512\n",
      "            ReLU-335          [-1, 256, 14, 14]               0\n",
      "          Conv2d-336         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-337         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-338         [-1, 1024, 14, 14]               0\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "            ReLU-350         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-351         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-352          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-353          [-1, 256, 14, 14]             512\n",
      "            ReLU-354          [-1, 256, 14, 14]               0\n",
      "          Conv2d-355          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-356          [-1, 256, 14, 14]             512\n",
      "            ReLU-357          [-1, 256, 14, 14]               0\n",
      "          Conv2d-358         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-359         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-360         [-1, 1024, 14, 14]               0\n",
      "            ReLU-361         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-362         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-363          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-364          [-1, 256, 14, 14]             512\n",
      "            ReLU-365          [-1, 256, 14, 14]               0\n",
      "          Conv2d-366          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-367          [-1, 256, 14, 14]             512\n",
      "            ReLU-368          [-1, 256, 14, 14]               0\n",
      "          Conv2d-369         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-370         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-371         [-1, 1024, 14, 14]               0\n",
      "            ReLU-372         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-373         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-378          [-1, 256, 14, 14]             512\n",
      "            ReLU-379          [-1, 256, 14, 14]               0\n",
      "          Conv2d-380         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-381         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-382         [-1, 1024, 14, 14]               0\n",
      "            ReLU-383         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-384         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-385          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-386          [-1, 256, 14, 14]             512\n",
      "            ReLU-387          [-1, 256, 14, 14]               0\n",
      "          Conv2d-388          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-389          [-1, 256, 14, 14]             512\n",
      "            ReLU-390          [-1, 256, 14, 14]               0\n",
      "          Conv2d-391         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-392         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-393         [-1, 1024, 14, 14]               0\n",
      "            ReLU-394         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-395         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-396          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-397          [-1, 256, 14, 14]             512\n",
      "            ReLU-398          [-1, 256, 14, 14]               0\n",
      "          Conv2d-399          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-400          [-1, 256, 14, 14]             512\n",
      "            ReLU-401          [-1, 256, 14, 14]               0\n",
      "          Conv2d-402         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-403         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-404         [-1, 1024, 14, 14]               0\n",
      "            ReLU-405         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-406         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-407          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-408          [-1, 256, 14, 14]             512\n",
      "            ReLU-409          [-1, 256, 14, 14]               0\n",
      "          Conv2d-410          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-411          [-1, 256, 14, 14]             512\n",
      "            ReLU-412          [-1, 256, 14, 14]               0\n",
      "          Conv2d-413         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-414         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-415         [-1, 1024, 14, 14]               0\n",
      "            ReLU-416         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-417         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-418          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-419          [-1, 256, 14, 14]             512\n",
      "            ReLU-420          [-1, 256, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-425         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-426         [-1, 1024, 14, 14]               0\n",
      "            ReLU-427         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-428         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-429          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-430          [-1, 256, 14, 14]             512\n",
      "            ReLU-431          [-1, 256, 14, 14]               0\n",
      "          Conv2d-432          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-433          [-1, 256, 14, 14]             512\n",
      "            ReLU-434          [-1, 256, 14, 14]               0\n",
      "          Conv2d-435         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-436         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-437         [-1, 1024, 14, 14]               0\n",
      "            ReLU-438         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-439         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-440          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-441          [-1, 256, 14, 14]             512\n",
      "            ReLU-442          [-1, 256, 14, 14]               0\n",
      "          Conv2d-443          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-444          [-1, 256, 14, 14]             512\n",
      "            ReLU-445          [-1, 256, 14, 14]               0\n",
      "          Conv2d-446         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-447         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-448         [-1, 1024, 14, 14]               0\n",
      "            ReLU-449         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "            ReLU-460         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-461         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-462          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-463          [-1, 256, 14, 14]             512\n",
      "            ReLU-464          [-1, 256, 14, 14]               0\n",
      "          Conv2d-465          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-466          [-1, 256, 14, 14]             512\n",
      "            ReLU-467          [-1, 256, 14, 14]               0\n",
      "          Conv2d-468         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-469         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-470         [-1, 1024, 14, 14]               0\n",
      "            ReLU-471         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-472         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-473          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-474          [-1, 256, 14, 14]             512\n",
      "            ReLU-475          [-1, 256, 14, 14]               0\n",
      "          Conv2d-476          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-477          [-1, 256, 14, 14]             512\n",
      "            ReLU-478          [-1, 256, 14, 14]               0\n",
      "          Conv2d-479         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-480         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-481         [-1, 1024, 14, 14]               0\n",
      "            ReLU-482         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-483         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-484          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-485          [-1, 256, 14, 14]             512\n",
      "            ReLU-486          [-1, 256, 14, 14]               0\n",
      "          Conv2d-487          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-488          [-1, 256, 14, 14]             512\n",
      "            ReLU-489          [-1, 256, 14, 14]               0\n",
      "          Conv2d-490         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-491         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-492         [-1, 1024, 14, 14]               0\n",
      "            ReLU-493         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-494         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-495          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-496          [-1, 256, 14, 14]             512\n",
      "            ReLU-497          [-1, 256, 14, 14]               0\n",
      "          Conv2d-498          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-499          [-1, 256, 14, 14]             512\n",
      "            ReLU-500          [-1, 256, 14, 14]               0\n",
      "          Conv2d-501         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-502         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-503         [-1, 1024, 14, 14]               0\n",
      "            ReLU-504         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-505         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-506          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-507          [-1, 256, 14, 14]             512\n",
      "            ReLU-508          [-1, 256, 14, 14]               0\n",
      "          Conv2d-509          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-510          [-1, 256, 14, 14]             512\n",
      "            ReLU-511          [-1, 256, 14, 14]               0\n",
      "          Conv2d-512         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-513         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-514         [-1, 1024, 14, 14]               0\n",
      "            ReLU-515         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-516         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-517          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-518          [-1, 256, 14, 14]             512\n",
      "            ReLU-519          [-1, 256, 14, 14]               0\n",
      "          Conv2d-520          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-521          [-1, 256, 14, 14]             512\n",
      "            ReLU-522          [-1, 256, 14, 14]               0\n",
      "          Conv2d-523         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-524         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-525         [-1, 1024, 14, 14]               0\n",
      "            ReLU-526         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-527         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-528          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-529          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-530          [-1, 512, 14, 14]               0\n",
      "          Conv2d-531            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-532            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-533            [-1, 512, 7, 7]               0\n",
      "          Conv2d-534           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-535           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-536           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-537           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-538           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-539           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-540           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-541            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-542            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-543            [-1, 512, 7, 7]               0\n",
      "          Conv2d-544            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-545            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-546            [-1, 512, 7, 7]               0\n",
      "          Conv2d-547           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-548           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-549           [-1, 2048, 7, 7]               0\n",
      "            ReLU-550           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-551           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-552            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-553            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-554            [-1, 512, 7, 7]               0\n",
      "          Conv2d-555            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-556            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-557            [-1, 512, 7, 7]               0\n",
      "          Conv2d-558           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-559           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-560           [-1, 2048, 7, 7]               0\n",
      "            ReLU-561           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-562           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-563           [-1, 2048, 1, 1]               0\n",
      "          Linear-564                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 60,192,808\n",
      "Trainable params: 60,192,808\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 706.89\n",
      "Params size (MB): 229.62\n",
      "Estimated Total Size (MB): 937.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model152 = resnet152().to(device=device)\n",
    "summary(model152,(3,224,224))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "b1380083",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
